{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43381ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt, pandas as pd, time\n",
    "import warnings, json, sys, requests, gzip, io, urllib, requests, os\n",
    "\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from penquins import Kowalski\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from bson.json_util import loads, dumps\n",
    "from astropy.io import fits\n",
    "from astropy.io.fits.verify import VerifyWarning \n",
    "warnings.filterwarnings(\"ignore\", category=VerifyWarning)\n",
    "\n",
    "import tqdm\n",
    "\n",
    "BOLD = \"\\033[1m\"; END  = \"\\033[0m\"\n",
    "\n",
    "with open('/Users/nabeelr/credentials.json', 'r') as f:\n",
    "    creds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72863b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"Times New Roman\",\n",
    "    \"font.size\": 12,\n",
    "})\n",
    "plt.rcParams['axes.linewidth'] = 1\n",
    "\n",
    "k = Kowalski(username=creds['kowalski_username'], password=creds['kowalski_password'])\n",
    "api_token = creds['fritz_api_key']\n",
    "assert(k.ping())\n",
    "\n",
    "external_HDD = \"/Volumes/NRExternal3/trainv6 data/\"\n",
    "to_desktop = \"/Users/nabeelr/Desktop/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b702101a",
   "metadata": {},
   "source": [
    "### Query the BTS Sample Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b5b928",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Old queries\n",
    "# bts_trues_url      = \"https://sites.astro.caltech.edu/ztf/bts/explorer.php?f=s&subsample=trans&classstring=&classexclude=&ps1img=y&lcfig=y&ztflink=lasair&lastdet=&startsavedate=&startpeakdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=&startabsmag=&starthostabs=&starthostcol=&startb=&startav=&endsavedate=&endpeakdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=18.5&endabsmag=&endhostabs=&endhostcol=&endb=&endav=&sort=peakmag&format=csv\"\n",
    "# bts_dim_falses_url = \"https://sites.astro.caltech.edu/ztf/bts/explorer.php?f=s&subsample=trans&classstring=&classexclude=&quality=y&purity=y&ps1img=y&lcfig=y&ztflink=lasair&lastdet=&startsavedate=&startpeakdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=18.5&startabsmag=&starthostabs=&starthostcol=&startb=&startav=&endsavedate=&endpeakdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=&endabsmag=&endhostabs=&endhostcol=&endb=&endav=&sort=peakmag&reverse=y&format=csv\"\n",
    "\n",
    "# bts_trues_url      = \"https://sites.astro.caltech.edu/ztf/bts/explorer.php?f=s&subsample=trans&classstring=&classexclude=&passok=y&refok=y&dateok=y&purity=y&ps1img=y&lcfig=y&ztflink=lasair&lastdet=&startsavedate=&startpeakdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=&startabsmag=&starthostabs=&starthostcol=&startb=&startav=&endsavedate=&endpeakdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=18.5&endabsmag=&endhostabs=&endhostcol=&endb=&endav=&sort=peakmag&format=csv\"\n",
    "# bts_var_falses_url = \"https://sites.astro.caltech.edu/ztf/bts/explorer.php?f=s&subsample=var&classstring=&classexclude=&ztflink=lasair&lastdet=&startsavedate=&startpeakdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=&startabsmag=&starthostabs=&starthostcol=&startb=&startav=&endsavedate=&endpeakdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=&endabsmag=&endhostabs=&endhostcol=&endb=&endav=&format=csv\"\n",
    "# bts_dim_falses_url = \"https://sites.astro.caltech.edu/ztf/bts/explorer.php?f=s&subsample=trans&classstring=&classexclude=&passok=y&refok=y&dateok=y&purity=y&ps1img=y&lcfig=y&ztflink=lasair&lastdet=&startsavedate=&startpeakdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=18.5&startabsmag=&starthostabs=&starthostcol=&startb=&startav=&endsavedate=&endpeakdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=&endabsmag=&endhostabs=&endhostcol=&endb=&endav=&sort=peakmag&reverse=y&format=csv\"\n",
    "\n",
    "# # v2\n",
    "# query_urls = {\n",
    "#     \"rcf_trues\":           \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&samprcf=y&subsample=trans&classstring=&classexclude=&refok=y&purity=y&ps1img=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=18.5&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\",\n",
    "#     \"rcf_dim_falses\":      \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&samprcf=y&subsample=trans&classstring=&classexclude=&covok=y&refok=y&purity=y&ps1img=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=18.5&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\",\n",
    "#     \"rcf_var_falses\":      \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&samprcf=y&subsample=var&classstring=&classexclude=&refok=y&ps1img=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\",\n",
    "\n",
    "#     \"rcf_deep_trues\"     : \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&sampdeep=y&subsample=trans&classstring=&classexclude=&refok=y&purity=y&ps1img=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=18.5&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\",\n",
    "#     \"rcf_deep_dim_falses\": \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&sampdeep=y&subsample=trans&classstring=&classexclude=&covok=y&refok=y&purity=y&ps1img=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=18.5&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\",\n",
    "#     \"rcf_deep_var_falses\": \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&sampdeep=y&subsample=var&classstring=&classexclude=&refok=y&ps1img=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\"\n",
    "# }\n",
    "\n",
    "# # v3.1\n",
    "# query_urls = {\n",
    "#     \"rcf_trues\":    \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&samprcf=y&sampdeep=y&subsample=trans&classstring=&classexclude=&refok=y&purity=y&ps1img=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=18.5&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\",\n",
    "#     \"rcf_dim\":      \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&samprcf=y&subsample=all&classstring=&classexclude=&covok=y&refok=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=18.5&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\",\n",
    "#     \"rcf_var\":      \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&samprcf=y&subsample=var&classstring=&classexclude=&refok=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\",\n",
    "    \n",
    "#     \"rcf_deep_dim\": \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&sampdeep=y&subsample=all&classstring=&classexclude=&covok=y&refok=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=18.5&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\",\n",
    "#     \"rcf_deep_var\": \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&sampdeep=y&subsample=var&classstring=&classexclude=&refok=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\"\n",
    "# }\n",
    "\n",
    "# # v3.2 (no changes to v4)\n",
    "# query_urls = {\n",
    "#     \"trues\": \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&samprcf=y&sampdeep=y&subsample=trans&classstring=&classexclude=&refok=y&purity=y&ps1img=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=18.5&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\",\n",
    "#     \"dims\":  \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&samprcf=y&sampdeep=y&subsample=all&classstring=&classexclude=&covok=y&refok=y&purity=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=18.5&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\",\n",
    "#     \"vars\":  \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&samprcf=y&sampdeep=y&subsample=var&classstring=&classexclude=&refok=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\",\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e49774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v4 & v5 & v6\n",
    "query_urls = {\n",
    "    \"trues\": \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&samprcf=y&sampdeep=y&subsample=trans&classstring=&classexclude=&refok=y&purity=y&ps1img=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=18.5&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\",\n",
    "    \"vars\":  \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&samprcf=y&sampdeep=y&subsample=var&classstring=&classexclude=&refok=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\",\n",
    "    \"dims\":  \"http://sites.astro.caltech.edu/ztf/rcf/explorer.php?f=s&coverage=any&samprcf=y&sampdeep=y&subsample=all&classstring=&classexclude=&covok=y&refok=y&purity=y&lcfig=y&ztflink=fritz&startsavedate=&startpeakdate=&startlastdate=&startra=&startdec=&startz=&startdur=&startrise=&startfade=&startpeakmag=18.5&startlastmag=&startabsmag=&starthostabs=&starthostcol=&startsavevis=&startlatevis=&startcurrvis=&startb=&startav=&endsavedate=&endpeakdate=&endlastdate=&endra=&enddec=&endz=&enddur=&endrise=&endfade=&endpeakmag=&endlastmag=&endabsmag=&endhostabs=&endhostcol=&endsavevis=&endlatevis=&endcurrvis=&endb=&endav=&sort=peakmag&format=csv\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011d143",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for set_name in query_urls.keys():\n",
    "    with open(f\"data/base_data/{set_name}.csv\", \"w\") as f:\n",
    "        f.write(requests.get(query_urls[set_name], auth=(creds[\"btsse_username\"], creds[\"btsse_password\"])).text)\n",
    "        print(\"Queried and wrote\", set_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36242947",
   "metadata": {},
   "source": [
    "### Read queried data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b0c0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name1 in query_urls.keys():\n",
    "    set1 = pd.read_csv(f\"data/base_data/{name1}.csv\")\n",
    "    print(name1)\n",
    "    for name2 in query_urls.keys():\n",
    "        set2 = pd.read_csv(f\"data/base_data/{name2}.csv\")\n",
    "        print(f\"  in {name2}\")\n",
    "        print(\"  \", np.sum(set1['ZTFID'].isin(set2[\"ZTFID\"])), \"/\", len(set1['ZTFID']))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a9abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_queries = pd.DataFrame(columns=[\"ZTFID\"])\n",
    "queries = [pd.read_csv(f\"data/base_data/{set_name}.csv\") for set_name in query_urls.keys()]\n",
    "\n",
    "for i in range(len(queries)):\n",
    "    queries[i] = queries[i][~queries[i][\"type\"].isin([\"bogus\", \"duplicate\", \"bogus?\", \"duplicate?\"])]\n",
    "    queries[i] = queries[i][~queries[i]['ZTFID'].isin(all_queries['ZTFID'])]\n",
    "    all_queries = pd.concat([all_queries, queries[i]])\n",
    "    \n",
    "trues = queries[0]\n",
    "dims  = queries[1]\n",
    "vars  = queries[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a36d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trues), \"rcf true sources\")\n",
    "print(f\"{len(dims)}+{len(vars)}={len(dims)+len(vars)} rcf (deep) false sources\")\n",
    "\n",
    "print(len(all_queries), \"total\")\n",
    "\n",
    "# v2\n",
    "# 7009 total\n",
    "\n",
    "# v3.1\n",
    "# 4150 rcf true sources\n",
    "# 7913 rcf (deep) false sources\n",
    "# 12063 total\n",
    "\n",
    "# v3.2, v4\n",
    "# 4476 rcf true sources\n",
    "# 8749 rcf (deep) false sources\n",
    "# 13225 total\n",
    "\n",
    "# v5\n",
    "# 4476 rcf true sources\n",
    "# 1083+7590=8673 rcf (deep) false sources\n",
    "# 13149 total\n",
    "\n",
    "# v6\n",
    "# 5158 rcf true sources\n",
    "# 1123+8822=9945 rcf (deep) false sources\n",
    "# 15103 total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a7a78",
   "metadata": {},
   "source": [
    "### Process list from Mat Smith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58defe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "extIas = pd.read_csv('data/base_data/external_Ias.csv')\n",
    "extIas.rename(columns={\"ztfname\": \"ZTFID\"}, inplace=True)\n",
    "print(\"Total in extIas list\", len(extIas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonZTF = ~extIas['ZTFID'].str.contains('ZTF')\n",
    "nonZTF_idxs = extIas['ZTFID'].index[nonZTF]\n",
    "\n",
    "extIas = extIas.drop(index=nonZTF_idxs)\n",
    "print(\"Total in extIas list excluding non ZTF objects\", len(extIas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bdb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inBTSSE = extIas['ZTFID'].isin(all_queries['ZTFID'])\n",
    "inBTSSE_idxs = extIas['ZTFID'].index[inBTSSE]\n",
    "\n",
    "extIas = extIas_Ias.drop(index=inBTSSE_idxs)\n",
    "print(\"New in extIas list\", len(extIas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa58be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total objects:\", len(all_queries)+len(extIas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da84241b",
   "metadata": {},
   "source": [
    "### Process list of BTS Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffca2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejects = pd.read_csv('data/base_data/rejects.csv')\n",
    "print(\"Total in rejects list\", len(rejects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574aacfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejects = rejects[~rejects['ZTFID'].str.contains(\"ZTF23\")]\n",
    "print(\"Total rejects before 2023\", len(rejects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a196d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inBTSSE = rejects['ZTFID'].isin(all_queries['ZTFID'])\n",
    "inBTSSE_idxs = rejects['ZTFID'].index[inBTSSE]\n",
    "rejects = rejects.drop(index=inBTSSE_idxs)\n",
    "\n",
    "inextIas = rejects['ZTFID'].isin(extIas['ZTFID'])\n",
    "inextIas_idxs = rejects['ZTFID'].index[inextIas]\n",
    "rejects = rejects.drop(index=inextIas_idxs)\n",
    "\n",
    "print(\"New in rejects list\", len(rejects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total objects:\", len(all_queries)+len(extIas)+len(rejects))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4578ff4e",
   "metadata": {},
   "source": [
    "### Objects to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e7e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "objs_to_remove = [\"ZTF18abdiasx\", \"ZTF21abyazip\", \"ZTF18aaadqua\", \"ZTF18aarrwmi\", \n",
    "                  \"ZTF18aazijke\", \"ZTF18abncsdn\", \"ZTF18aaslhxt\", \"ZTF18aamigmk\", \n",
    "                  \"ZTF18abdpvnd\", \"ZTF18aaqffyp\"]\n",
    "\n",
    "for obj in objs_to_remove:\n",
    "    trues = trues[trues[\"ZTFID\"] != obj]\n",
    "    dims = dims[dims[\"ZTFID\"] != obj]\n",
    "    vars = vars[vars[\"ZTFID\"] != obj]\n",
    "    extIas = extIas[extIas[\"ZTFID\"] != obj]\n",
    "    rejects = rejects[rejects[\"ZTFID\"] != obj]\n",
    "\n",
    "queries = (trues, dims, vars) \n",
    "all_queries = pd.concat(queries)\n",
    "all_ZTFIDs = np.concatenate((all_queries[\"ZTFID\"].to_numpy(), extIas['ZTFID'].to_numpy(), rejects['ZTFID'].to_numpy()))\n",
    "print(\"Final number of objects:\", len(all_ZTFIDs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c51d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00c471c2",
   "metadata": {},
   "source": [
    "### Helper functions for querying kowalski and processing alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f2cd5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def query_fritz(ZTFID, normalize=True, verbose=False):\n",
    "    \"\"\"\n",
    "    Query fritz for alerts with cutouts for a (list of) ZTFID(s)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ZTFID: string or list\n",
    "        Object IDs to query for (e.g. ZTF22abwqedu)\n",
    "    \n",
    "    normalize (optional): bool\n",
    "        normalize cutouts by the Frobenius norm (L2) \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    alerts: list of dicts\n",
    "        each element in list is an alert\n",
    "        alert keys include \n",
    "\n",
    "    ----------------------------------------------------------\n",
    "    ADAPTED FROM https://github.com/growth-astro/ztfrest/\n",
    "    https://zwickytransientfacility.github.io/ztf-avro-alert/schema.html\n",
    "    \"\"\"\n",
    "    \n",
    "    # Deal with provided input being a single ZTF object (string) and multiple (list)\n",
    "    if type(ZTFID) == str:\n",
    "        list_ZTFID = [ZTFID]\n",
    "    elif type(ZTFID) == list:\n",
    "        list_ZTFID = ZTFID\n",
    "    else:\n",
    "        print(f\"{ZTFID} must be a list or a string\")\n",
    "        return None\n",
    "\n",
    "    # Set up query details\n",
    "    host = \"https://fritz.science\"\n",
    "    metadata_endpoint = \"alerts\"\n",
    "    triplets_endpoint = \"alerts_triplets\"\n",
    "    headers = {'Authorization': f'token {api_token}'}\n",
    "    \n",
    "    alerts = []\n",
    "    \n",
    "    # For each object requested ...\n",
    "    for ZTFID in list_ZTFID:\n",
    "        # Set up metadata api endpoint url and execute request\n",
    "        url = urllib.parse.urljoin(host, f'/api/{metadata_endpoint}/{ZTFID}')\n",
    "        r = requests.get(url, headers=headers, params={})\n",
    "        \n",
    "        try:\n",
    "            object_alerts = r.json()['data']\n",
    "        except:\n",
    "            # Query response does not have any data - failed query (connection or permissions)\n",
    "            print(r.json())\n",
    "        \n",
    "        if object_alerts == []:\n",
    "            # No alerts recieved - possibly because of permissions\n",
    "            print(\"  No data for\", ZTFID)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"queried {len(object_alerts)} alerts of {ZTFID}\")\n",
    "            \n",
    "        # some images will be corrupted, initialize array to log which to exclude\n",
    "        to_drop = np.array((), dtype=int)\n",
    "            \n",
    "        # For each alert ...\n",
    "        for i in range(len(object_alerts)):\n",
    "            # candidate and classifications are two dicts nested within the alert dict\n",
    "            # This merges those two dicts and does away with the unncessary data in the alert dict\n",
    "            alert = object_alerts[i]['candidate'] | object_alerts[i]['classifications']\n",
    "            alert[\"candid\"] = object_alerts[i]['candid']\n",
    "            \n",
    "            # Set up triplets api endpoint url and execute request\n",
    "            params={\"candid\": alert[\"candid\"], \"normalizeImage\": normalize}\n",
    "            url = urllib.parse.urljoin(host, f'/api/{triplets_endpoint}/{ZTFID}')\n",
    "            r = requests.get(url, headers=headers, params=params)\n",
    "            \n",
    "            # Inset triplet into alert dict\n",
    "            alert['triplet'] = np.asarray(r.json()['data']['triplet'])\n",
    "            \n",
    "            # Note the alert/triplet index where a cutout was found to be corrupted \n",
    "            if r.json()['data']['image_corrupt']:\n",
    "                to_drop = np.append(to_drop, int(i))\n",
    "                \n",
    "            object_alerts[i] = alert\n",
    "        \n",
    "        # Delete corresponding triplets and alerts that had corrupted cutouts\n",
    "        if len(to_drop) > 0:\n",
    "            object_alerts = np.delete(object_alerts, list(to_drop), axis=0)\n",
    "        \n",
    "        alerts += list(object_alerts)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"queried {len(object_alerts)} triplets of {ZTFID}\")\n",
    "            print(\"  Finished querying\", ZTFID)\n",
    "    if verbose:\n",
    "        print(BOLD+f\"Finished all queries, got {len(alerts)} alerts\"+END+\"\\n\")\n",
    "    return alerts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed0e0d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def query_kowalski(ZTFID, kowalski, programid, normalize : bool = True, verbose : bool = False, save_raw = None, load_raw = None):\n",
    "    \"\"\"\n",
    "    Query kowalski for alerts with cutouts for a (list of) ZTFID(s)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ZTFID: string or list\n",
    "        Object IDs to query for (e.g. ZTF22abwqedu)\n",
    "    \n",
    "    kowalski:\n",
    "        a kowalski api object created with the kowalski library\n",
    "        \n",
    "    normalize (optional): bool\n",
    "        normalize cutouts by the Frobenius norm (L2)\n",
    "        \n",
    "    programid:\n",
    "        which program to pull alerts from (1=public, 2=collab, 3=caltech mode)\n",
    "        \n",
    "    verbose (optional): bool\n",
    "        print diagnostics after each query\n",
    "        \n",
    "    save_raw (optional): str\n",
    "        if provided, all query results will be individually saved to disk at this path before any processsing is done\n",
    "        \n",
    "    load_raw (optional): str\n",
    "        if provided, check for existing file at this path before querying, load file and continue processing as if just queried\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    alerts: list of dicts\n",
    "        each dict represents alert\n",
    "        alert columns include jd, ra, dec, candid, acai and braii scores, magpsf, cutouts, etc.\n",
    "        \n",
    "    \n",
    "    ADAPTED FROM https://github.com/growth-astro/ztfrest/\n",
    "    https://zwickytransientfacility.github.io/ztf-avro-alert/schema.html\n",
    "    \"\"\"\n",
    "    \n",
    "    # Deal with provided input being a single ZTF object (string) and multiple (list)\n",
    "    if type(ZTFID) == str:\n",
    "        list_ZTFID = [ZTFID]\n",
    "    elif type(ZTFID) == list:\n",
    "        list_ZTFID = ZTFID\n",
    "    else:\n",
    "        print(f\"{ZTFID} must be a list or a string\")\n",
    "        return None\n",
    "\n",
    "    alerts = []\n",
    "    \n",
    "    # For each object requested ...\n",
    "    for ZTFID in list_ZTFID:\n",
    "        # Set up query\n",
    "        query = {\n",
    "            \"query_type\": \"find\",\n",
    "            \"query\": {\n",
    "                \"catalog\": \"ZTF_alerts\",\n",
    "                \"filter\": {\n",
    "                    # take only alerts for specified object\n",
    "                    'objectId': ZTFID,\n",
    "                    # take only alerts with specified programid\n",
    "                    \"candidate.programid\": programid,\n",
    "                },\n",
    "                # what quantities to recieve \n",
    "                \"projection\": {\n",
    "                    \"_id\": 0,\n",
    "                    \"objectId\": 1,\n",
    "                    \n",
    "                    \"candidate.candid\": 1,\n",
    "                    \"candidate.fid\": 1,\n",
    "                    \"candidate.isdiffpos\": 1,\n",
    "                    \"candidate.ndethist\": 1,\n",
    "                    \"candidate.ncovhist\": 1,\n",
    "                    \"candidate.sky\": 1,\n",
    "                    \"candidate.fwhm\": 1,\n",
    "                    \"candidate.seeratio\": 1,\n",
    "                    \"candidate.mindtoedge\": 1,\n",
    "                    \"candidate.nneg\": 1,\n",
    "                    \"candidate.nbad\": 1,\n",
    "                    \"candidate.scorr\": 1,\n",
    "                    \"candidate.dsnrms\": 1,\n",
    "                    \"candidate.ssnrms\": 1,\n",
    "                    \"candidate.exptime\": 1,\n",
    "                    \n",
    "                    \"candidate.field\": 1,\n",
    "                    \"candidate.jd\": 1,\n",
    "                    \"candidate.ra\": 1,\n",
    "                    \"candidate.dec\": 1,\n",
    "                    \n",
    "                    \"candidate.magpsf\": 1,\n",
    "                    \"candidate.sigmapsf\": 1,\n",
    "                    \"candidate.diffmaglim\": 1,\n",
    "                    \"candidate.magap\": 1,\n",
    "                    \"candidate.sigmagap\": 1,\n",
    "                    \"candidate.magapbig\": 1,\n",
    "                    \"candidate.sigmagapbig\": 1,\n",
    "                    \"candidate.magdiff\": 1,\n",
    "                    \"candidate.magzpsci\": 1,\n",
    "                    \"candidate.magzpsciunc\": 1,\n",
    "                    \"candidate.magzpscirms\": 1,\n",
    "                    \n",
    "                    \"candidate.distnr\": 1,\n",
    "                    \"candidate.magnr\": 1,\n",
    "                    \"candidate.sigmanr\": 1,\n",
    "                    \"candidate.chinr\": 1,\n",
    "                    \"candidate.sharpnr\": 1,\n",
    "                    \n",
    "                    \"candidate.neargaia\": 1,\n",
    "                    \"candidate.neargaiabright\": 1,\n",
    "                    \"candidate.maggaia\": 1,\n",
    "                    \"candidate.maggaiabright\": 1,    \n",
    "                    \n",
    "                    \"candidate.drb\": 1,\n",
    "                    \"candidate.classtar\": 1,\n",
    "                    \"candidate.sgscore1\": 1,\n",
    "                    \"candidate.distpsnr1\": 1,\n",
    "                    \"candidate.sgscore2\": 1,\n",
    "                    \"candidate.distpsnr2\": 1,\n",
    "                    \"candidate.sgscore3\": 1,\n",
    "                    \"candidate.distpsnr3\": 1,\n",
    "                    \n",
    "                    \"candidate.jdstarthist\": 1,\n",
    "                \n",
    "                    \"candidate.sgmag1\": 1,\n",
    "                    \"candidate.srmag1\": 1,\n",
    "                    \"candidate.simag1\": 1,\n",
    "                    \"candidate.szmag1\": 1,\n",
    "\n",
    "                    \"candidate.sgmag2\": 1,\n",
    "                    \"candidate.srmag2\": 1,\n",
    "                    \"candidate.simag2\": 1,\n",
    "                    \"candidate.szmag2\": 1,\n",
    "\n",
    "                    \"candidate.sgmag3\": 1,\n",
    "                    \"candidate.srmag3\": 1,\n",
    "                    \"candidate.simag3\": 1,\n",
    "                    \"candidate.szmag3\": 1,\n",
    "\n",
    "                    \"candidate.nmtchps\": 1,\n",
    "                                        \n",
    "                    \"classifications.acai_h\": 1,\n",
    "                    \"classifications.acai_v\": 1,\n",
    "                    \"classifications.acai_o\": 1,\n",
    "                    \"classifications.acai_n\": 1,\n",
    "                    \"classifications.acai_b\": 1,\n",
    "                    \n",
    "                    \"cutoutScience\": 1,\n",
    "                    \"cutoutTemplate\": 1,\n",
    "                    \"cutoutDifference\": 1,\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        object_alerts = None\n",
    "        existing_data_path = None\n",
    "        \n",
    "        # Check if file path is provided for locating preloaded data\n",
    "        if type(load_raw) == str:\n",
    "            existing_data_path = os.path.join(load_raw, f\"{ZTFID}_prog{programid}.npy\")\n",
    "            \n",
    "            if os.path.exists(existing_data_path):\n",
    "                # Read existing data\n",
    "                object_alerts = np.load(existing_data_path, allow_pickle=True)\n",
    "                print(f\"    loaded existing data for {ZTFID}\")\n",
    "            else:\n",
    "                print(f\"    could not find existing data for {ZTFID}\")\n",
    "                existing_data_path = None\n",
    "        \n",
    "        # if opting to not use preloaded data or preloaded data couldn't be found\n",
    "        if object_alerts is None:\n",
    "            # Execute query\n",
    "            r = kowalski.query(query)\n",
    "            \n",
    "            if r['data'] == []:\n",
    "                # No alerts recieved - possibly by failed query (connection or permissions)\n",
    "                print(f\"  No programid={programid} data for\", ZTFID)\n",
    "                continue\n",
    "            else:\n",
    "                # returned data is list of dicts, each dict is an alert packet\n",
    "                object_alerts = r['data']   \n",
    "\n",
    "        # Only try to save raw data if preloaded data couldn't be found\n",
    "        if existing_data_path is None:\n",
    "            if type(save_raw) == str:\n",
    "                if not os.path.exists(save_raw):\n",
    "                    os.makedirs(save_raw)\n",
    "                np.save(os.path.join(save_raw, f\"{ZTFID}_prog{programid}\"), object_alerts)\n",
    "            elif save_raw is not None:\n",
    "                print(f\"Could not find save directory: {save_raw}\")\n",
    "                print(\"No queries will be saved\")\n",
    "                save_raw = None\n",
    "\n",
    "        # initialize empty array to contain triplets\n",
    "        triplets = np.empty((len(object_alerts), 63, 63, 3))\n",
    "        # some images will be corrupted, initialize array to log which to exclude\n",
    "        to_drop = np.array((), dtype=int)\n",
    "\n",
    "        # For each alert ...\n",
    "        for i, alert in enumerate(object_alerts):\n",
    "            # Unzip fits files of cutouts\n",
    "            triplets[i], drop = make_triplet(alert, normalize=normalize)\n",
    "\n",
    "            # Note the alert/triplet index where a cutout was found to be corrupted \n",
    "            if drop:\n",
    "                to_drop = np.append(to_drop, int(i))\n",
    "\n",
    "        # Delete corresponding triplets and alerts that had corrupted cutouts\n",
    "        if len(to_drop) > 0:\n",
    "            triplets = np.delete(triplets, list(to_drop), axis=0)\n",
    "            object_alerts = np.delete(object_alerts, list(to_drop), axis=0)\n",
    "\n",
    "        # candidate and classifications are two dicts nested within the alert dict\n",
    "        # This merges those two dicts and does away with the unncessary data in the alert dict \n",
    "        # object_alerts = [alert['candidate'] | alert['classifications'] for alert in object_alerts]\n",
    "\n",
    "        # Add triplet to the alert dict\n",
    "        for alert, triplet in zip(object_alerts, triplets):\n",
    "            alert['triplet'] = triplet\n",
    "\n",
    "        alerts += list(object_alerts)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"  Finished {'loading' if existing_data_path else 'querying'}\", ZTFID)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Finished all programid={programid} queries, got {len(alerts)} alerts\\n\")\n",
    "    \n",
    "    return alerts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d561d072",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_triplet(alert, normalize: bool = True):\n",
    "    \"\"\"\n",
    "    Unpack binary fits files containing cutouts from kowalski\n",
    "    Helper function to query_kowalski()\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alert: dict\n",
    "        alert dictionary queried from kowlaski\n",
    "        see query_kowalski()\n",
    "    \n",
    "    normalize (optional): bool\n",
    "        normalize cutouts by the Frobenius norm (L2) \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    triplet: 63 x 63 x 3 array\n",
    "        3 channel 63 x 63 image representing the science, reference, and difference cutouts\n",
    "    \n",
    "    drop: bool\n",
    "        whether or not the file is found to be corrupted\n",
    "    \n",
    "    ----------------------------------------------------------\n",
    "    ADAPTED FROM https://github.com/dmitryduev/braai\n",
    "    \"\"\"\n",
    "    \n",
    "    cutout_dict = dict()\n",
    "    drop = False\n",
    "    \n",
    "    for cutout in ('science', 'template', 'difference'):\n",
    "        cutout_data = loads(dumps([alert[f'cutout{cutout.capitalize()}']['stampData']]))[0]\n",
    "        # unzip fits file\n",
    "        with gzip.open(io.BytesIO(cutout_data), 'rb') as f:\n",
    "            with fits.open(io.BytesIO(f.read())) as hdu:\n",
    "                data = hdu[0].data\n",
    "\n",
    "                # Compute median value of image to fill nans\n",
    "                medfill = np.nanmedian(data.flatten())\n",
    "                \n",
    "                # if the median is not a typical pixel value, image is corrupted; mark to be excluded\n",
    "                if medfill == np.nan or medfill == -np.inf or medfill == np.inf:\n",
    "                    print(alert['objectId'], \"bad medfill (nan or inf)\", alert['candidate']['candid'])\n",
    "                    drop = True\n",
    "                \n",
    "                # Fill in nans with median value\n",
    "                cutout_dict[cutout] = np.nan_to_num(data, nan=medfill)\n",
    "                \n",
    "                # normalize with L2 norm\n",
    "                if normalize and not drop:\n",
    "                    cutout_dict[cutout] /= np.linalg.norm(cutout_dict[cutout])\n",
    "                    \n",
    "                # If image is all zeros, image is corrupted; mark to be excluded\n",
    "                if np.all(cutout_dict[cutout].flatten() == 0):\n",
    "                    print(alert['objectId'], \"zero image\", alert['candidate']['candid'])\n",
    "                    drop=True\n",
    "                \n",
    "                # If any nans remain in image, image is corrupted; mark to be excluded\n",
    "                # Should never trigger because nans were already filled\n",
    "#                 if np.any(np.isnan(cutout_dict[cutout].flatten())):\n",
    "#                     print(alert['objectId'], \"nan here\", alert['candid'])\n",
    "#                     drop=True\n",
    "                    \n",
    "        # pad to 63x63 if smaller\n",
    "        shape = cutout_dict[cutout].shape\n",
    "        if shape != (63, 63):\n",
    "            print(\"bad shape\", shape, alert['candidate']['candid'], alert['objectId'])\n",
    "            # Fill value will have changed after normalizing so recompute\n",
    "            medfill = np.nanmedian(cutout_dict[cutout].flatten())\n",
    "            \n",
    "            # Execute padding\n",
    "            cutout_dict[cutout] = np.pad(cutout_dict[cutout],\n",
    "                                         [(0, 63 - shape[0]),\n",
    "                                          (0, 63 - shape[1])],\n",
    "                                          mode='constant', \n",
    "                                          constant_values=medfill)\n",
    "            \n",
    "    triplet = np.zeros((63, 63, 3))\n",
    "    triplet[:, :, 0] = cutout_dict['science']\n",
    "    triplet[:, :, 1] = cutout_dict['template']\n",
    "    triplet[:, :, 2] = cutout_dict['difference']\n",
    "    \n",
    "    return triplet, drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86846995",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_triplet(tr, show_fig: bool = True):\n",
    "    \"\"\"ADAPTED FROM https://github.com/dmitryduev/braai\"\"\"\n",
    "    fig = plt.figure(figsize=(8, 2), dpi=120)\n",
    "    \n",
    "    ax1 = fig.add_subplot(131)\n",
    "    ax1.axis('off')\n",
    "    ax1.imshow(tr[:, :, 0], origin='upper', cmap=plt.cm.bone, norm=LogNorm())\n",
    "    ax1.title.set_text('Science')\n",
    "    \n",
    "    ax2 = fig.add_subplot(132)\n",
    "    ax2.axis('off')\n",
    "    ax2.imshow(tr[:, :, 1], origin='upper', cmap=plt.cm.bone, norm=LogNorm())\n",
    "    ax2.title.set_text('Reference')\n",
    "    \n",
    "    ax3 = fig.add_subplot(133)\n",
    "    ax3.axis('off')\n",
    "    ax3.imshow(tr[:, :, 2], origin='upper', cmap=plt.cm.bone)\n",
    "    ax3.title.set_text('Difference')\n",
    "\n",
    "    if show_fig:\n",
    "        plt.show()\n",
    "    else:\n",
    "        return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf4e722",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def extract_triplets(alerts, normalize: bool = True, pop_triplet: bool = True):\n",
    "    \"\"\"\n",
    "    Takes in alerts (list of dicts) with key 'triplet', pops triplets out of alerts, \n",
    "    and returns alerts and triplets separated\n",
    "    \"\"\"\n",
    "    triplets = np.empty((len(alerts), 63, 63, 3))\n",
    "    for i, alert in enumerate(alerts):\n",
    "        triplets[i] = alert['triplet']\n",
    "        \n",
    "        if pop_triplet:\n",
    "            alert.pop('triplet'); alert.pop('cutoutScience'); alert.pop('cutoutTemplate'); alert.pop('cutoutDifference')\n",
    "        \n",
    "    return alerts, triplets\n",
    "\n",
    "\n",
    "def prep_alerts(alerts, label):\n",
    "    \"\"\"\n",
    "    takes in alerts (list of dicts) with nested dicts 'candidate' and 'classifications'\n",
    "    un-nests inner dicts and adds column containing provided labels\n",
    "    returns dataframe \n",
    "    \"\"\"\n",
    "    cand_class_data = [alert['candidate'] | alert['classifications'] for alert in alerts]\n",
    "\n",
    "    df = pd.DataFrame(cand_class_data)\n",
    "    df.insert(0, \"objectId\", [alert['objectId'] for alert in alerts])\n",
    "#     df.insert(1, \"candid\", [alert['candid'] for alert in alerts])\n",
    "    \n",
    "    # label must be int equalling 0, 1 or a list of 1s and 0s\n",
    "    if type(label) == list or type(label) == np.ndarray:\n",
    "        assert(len(label) == len(alerts))\n",
    "        df.insert(2, \"label\", label)\n",
    "    elif type(label) == int:    \n",
    "        df.insert(2, \"label\", np.full((len(alerts),), label, dtype=int))\n",
    "    print(\"Arranged candidate data and inserted labels\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b83d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trues.to_csv(\"data/base_data/trues_cleaned.csv\", index=None)\n",
    "# dims.to_csv(\"data/base_data/dims_cleaned.csv\", index=None)\n",
    "# vars.to_csv(\"data/base_data/vars_cleaned.csv\", index=None)\n",
    "# MS_Ias.to_csv(\"data/base_data/extIas_cleaned.csv\", index=None)\n",
    "# rejects.to_csv(\"data/base_data/rejects_cleaned.csv\", index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ba781",
   "metadata": {},
   "source": [
    "### Query data from kowalski, separate and save triplets and candidate data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbd986c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def download_training_data(source_df, set_name, kowalski, label, normalize_cutouts : bool = True, verbose : bool = False, save_raw = None, load_raw = None):\n",
    "    \"\"\"\n",
    "    Downloads alerts with cutouts from kowalski\n",
    "    Saves triplets in a .npy and alert metadata in a .csv\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    source_df: dataframe\n",
    "        dataframe with columns \"ZTFID\"\n",
    "    \n",
    "    kowalski:\n",
    "        a kowalski api object created with the penquins library\n",
    "        \n",
    "    label: int, array_like, or \"compute\"\n",
    "        BTS / not BTS label to assign to each alert in saved csv\n",
    "        if int (must be 0 or 1) assign all alerts provided label\n",
    "        if array_like (length must match number of alerts) assign from array in order\n",
    "        if \"compute\" assign all objects with any alert with magpsf < 18.5 label=1, otherwise 0\n",
    "        \n",
    "    normalize_cutouts (optional)- see query_kowalski()\n",
    "        \n",
    "    verbose (optional): bool\n",
    "        print diagnostics\n",
    "        \n",
    "    save_raw, load_raw (optional) - see query_kowalski()\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Querying kowalski for {len(source_df['ZTFID'])} objects of {set_name}\")\n",
    "        \n",
    "    alerts, triplets = extract_triplets(query_kowalski(source_df['ZTFID'].to_list(), k, 1, normalize=normalize_cutouts, \n",
    "                                                       verbose=verbose, save_raw=save_raw, load_raw=load_raw) + \n",
    "                                        query_kowalski(source_df['ZTFID'].to_list(), k, 2, normalize=normalize_cutouts, \n",
    "                                                       verbose=verbose, save_raw=save_raw, load_raw=load_raw))\n",
    "\n",
    "    np.save(f\"data/base_data/{set_name}_triplets.npy\", triplets)\n",
    "    del triplets\n",
    "    print(\"Saved and purged triplets\\n\")\n",
    "\n",
    "    num_alerts = len(alerts)\n",
    "    \n",
    "    if type(label) == int:\n",
    "        label = np.full((num_alerts), label, dtype=int)\n",
    "    elif type(label) == list or type(label) == np.ndarray:\n",
    "        label = label\n",
    "    elif label == \"compute\":\n",
    "        true_objs = set()\n",
    "        for alert in alerts: \n",
    "            if alert['candidate']['magpsf'] < 18.5:\n",
    "                true_objs.add(alert['objectId'])\n",
    "        label = np.asarray([1 if alert['objectId'] in true_objs else 0 for alert in alerts])\n",
    "    else:\n",
    "        print(f\"Could not understand label: {label}\")\n",
    "    \n",
    "    num_trues = np.sum(label == 1)\n",
    "    num_falses = np.sum(label == 0)\n",
    "    if num_trues + num_falses != len(label):\n",
    "        print(f\"Invalid labels provided: {label}\")\n",
    "    else:\n",
    "        print(f\"{set_name} {len(label)} total alerts: {num_trues} trues, {num_falses} falses\")\n",
    "\n",
    "    cand_data = prep_alerts(alerts, label)\n",
    "    cand_data.to_csv(f'data/base_data/{set_name}_candidates.csv', index=False)\n",
    "    del cand_data\n",
    "    print(\"Saved and purged candidate data\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = pd.read_csv(\"data/base_data/trues_cleaned.csv\", index_col=None)\n",
    "download_training_data(trues, \"trues\", k, label=1, normalize_cutouts=True, verbose=True, save_raw=external_HDD+\"trues\", load_raw=external_HDD+\"trues\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cae18a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = pd.read_csv(\"data/base_data/dims_cleaned.csv\", index_col=None)\n",
    "download_training_data(dims, \"dims\", k, label=0, normalize_cutouts=True, verbose=True, save_raw=external_HDD+\"dims\", load_raw=to_desktop+\"dims\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3820ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = pd.read_csv(\"data/base_data/vars_cleaned.csv\", index_col=None)\n",
    "download_training_data(vars, \"vars\", k, label=0, normalize_cutouts=True, verbose=True, save_raw=external_HDD+\"vars\", load_raw=external_HDD+\"vars\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68923979",
   "metadata": {},
   "outputs": [],
   "source": [
    "extIas = pd.read_csv(\"data/base_data/extIas_cleaned.csv\", index_col=None)\n",
    "download_training_data(extIas, \"extIas\", k, label='compute', normalize_cutouts=True, verbose=True, save_raw=external_HDD+\"extIas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c5b43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rejects = pd.read_csv(\"data/base_data/rejects_cleaned.csv\", index_col=None)\n",
    "download_training_data(rejects, \"rejects\", k, label=0, normalize_cutouts=True, verbose=True, save_raw=external_HDD+\"rejects\", load_raw=external_HDD+\"rejects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1047c0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "60a819b446826fec9589f2a4431338385350576f29c3491de1f269c234f42a28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
